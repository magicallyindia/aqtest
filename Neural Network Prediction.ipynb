{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import explained_variance_score, \\\n",
    "    mean_absolute_error, \\\n",
    "    median_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "#tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                     count       mean       std        min        25%  \\\ntemperatureMean      197.0  83.285072  4.785616  78.228333  79.299583   \ntemperatureMax       197.0  93.116650  5.210954  87.790000  88.890000   \ntemperatureMin       197.0  74.564873  4.465296  69.930000  70.990000   \ntemperatureMean_1    197.0  83.312329  4.771940  78.349167  79.347917   \ntemperatureMean_2    197.0  83.349818  4.761749  78.469167  79.352500   \ntemperatureMean_3    197.0  83.393234  4.756010  78.560417  79.374583   \ndewPoint_1           197.0  67.125939  4.704913  45.300000  65.470000   \ndewPoint_2           197.0  67.110203  4.718033  45.300000  65.470000   \ndewPoint_3           197.0  67.092538  4.732617  45.300000  65.470000   \nhumidity_1           197.0   0.622234  0.152667   0.230000   0.480000   \nhumidity_2           197.0   0.621371  0.152989   0.230000   0.480000   \nhumidity_3           197.0   0.620305  0.153520   0.230000   0.480000   \ntemperatureMax_1     197.0  93.153046  5.198585  87.910000  88.920000   \ntemperatureMax_2     197.0  93.202843  5.195089  88.030000  88.940000   \ntemperatureMax_3     197.0  93.259036  5.198720  88.140000  88.950000   \ntemperatureMin_1     197.0  74.582183  4.453832  70.060000  71.010000   \ntemperatureMin_2     197.0  74.603452  4.442115  70.170000  71.040000   \ntemperatureMin_3     197.0  74.635381  4.432682  70.230000  71.060000   \nprecipProbability_1  197.0   0.007665  0.026081   0.000000   0.000000   \nprecipProbability_2  197.0   0.008629  0.029131   0.000000   0.000000   \nprecipProbability_3  197.0   0.009289  0.030380   0.000000   0.000000   \n\n                           50%       75%         max  \ntemperatureMean      80.155417  88.09625   92.845833  \ntemperatureMax       89.740000  98.28000  106.580000  \ntemperatureMin       71.820000  78.11000   82.950000  \ntemperatureMean_1    80.155833  88.09625   92.845833  \ntemperatureMean_2    80.157917  88.09625   92.845833  \ntemperatureMean_3    80.269583  88.09625   92.845833  \ndewPoint_1           68.660000  70.53000   71.080000  \ndewPoint_2           68.660000  70.53000   71.080000  \ndewPoint_3           68.660000  70.53000   71.080000  \nhumidity_1            0.670000   0.76000    0.790000  \nhumidity_2            0.670000   0.76000    0.790000  \nhumidity_3            0.670000   0.76000    0.790000  \ntemperatureMax_1     89.740000  98.28000  106.580000  \ntemperatureMax_2     89.740000  98.28000  106.580000  \ntemperatureMax_3     89.830000  98.46000  106.580000  \ntemperatureMin_1     71.830000  78.11000   82.950000  \ntemperatureMin_2     71.830000  78.11000   82.950000  \ntemperatureMin_3     71.840000  78.11000   82.950000  \nprecipProbability_1   0.000000   0.00000    0.160000  \nprecipProbability_2   0.000000   0.00000    0.190000  \nprecipProbability_3   0.000000   0.00000    0.190000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>temperatureMean</th>\n      <td>197.0</td>\n      <td>83.285072</td>\n      <td>4.785616</td>\n      <td>78.228333</td>\n      <td>79.299583</td>\n      <td>80.155417</td>\n      <td>88.09625</td>\n      <td>92.845833</td>\n    </tr>\n    <tr>\n      <th>temperatureMax</th>\n      <td>197.0</td>\n      <td>93.116650</td>\n      <td>5.210954</td>\n      <td>87.790000</td>\n      <td>88.890000</td>\n      <td>89.740000</td>\n      <td>98.28000</td>\n      <td>106.580000</td>\n    </tr>\n    <tr>\n      <th>temperatureMin</th>\n      <td>197.0</td>\n      <td>74.564873</td>\n      <td>4.465296</td>\n      <td>69.930000</td>\n      <td>70.990000</td>\n      <td>71.820000</td>\n      <td>78.11000</td>\n      <td>82.950000</td>\n    </tr>\n    <tr>\n      <th>temperatureMean_1</th>\n      <td>197.0</td>\n      <td>83.312329</td>\n      <td>4.771940</td>\n      <td>78.349167</td>\n      <td>79.347917</td>\n      <td>80.155833</td>\n      <td>88.09625</td>\n      <td>92.845833</td>\n    </tr>\n    <tr>\n      <th>temperatureMean_2</th>\n      <td>197.0</td>\n      <td>83.349818</td>\n      <td>4.761749</td>\n      <td>78.469167</td>\n      <td>79.352500</td>\n      <td>80.157917</td>\n      <td>88.09625</td>\n      <td>92.845833</td>\n    </tr>\n    <tr>\n      <th>temperatureMean_3</th>\n      <td>197.0</td>\n      <td>83.393234</td>\n      <td>4.756010</td>\n      <td>78.560417</td>\n      <td>79.374583</td>\n      <td>80.269583</td>\n      <td>88.09625</td>\n      <td>92.845833</td>\n    </tr>\n    <tr>\n      <th>dewPoint_1</th>\n      <td>197.0</td>\n      <td>67.125939</td>\n      <td>4.704913</td>\n      <td>45.300000</td>\n      <td>65.470000</td>\n      <td>68.660000</td>\n      <td>70.53000</td>\n      <td>71.080000</td>\n    </tr>\n    <tr>\n      <th>dewPoint_2</th>\n      <td>197.0</td>\n      <td>67.110203</td>\n      <td>4.718033</td>\n      <td>45.300000</td>\n      <td>65.470000</td>\n      <td>68.660000</td>\n      <td>70.53000</td>\n      <td>71.080000</td>\n    </tr>\n    <tr>\n      <th>dewPoint_3</th>\n      <td>197.0</td>\n      <td>67.092538</td>\n      <td>4.732617</td>\n      <td>45.300000</td>\n      <td>65.470000</td>\n      <td>68.660000</td>\n      <td>70.53000</td>\n      <td>71.080000</td>\n    </tr>\n    <tr>\n      <th>humidity_1</th>\n      <td>197.0</td>\n      <td>0.622234</td>\n      <td>0.152667</td>\n      <td>0.230000</td>\n      <td>0.480000</td>\n      <td>0.670000</td>\n      <td>0.76000</td>\n      <td>0.790000</td>\n    </tr>\n    <tr>\n      <th>humidity_2</th>\n      <td>197.0</td>\n      <td>0.621371</td>\n      <td>0.152989</td>\n      <td>0.230000</td>\n      <td>0.480000</td>\n      <td>0.670000</td>\n      <td>0.76000</td>\n      <td>0.790000</td>\n    </tr>\n    <tr>\n      <th>humidity_3</th>\n      <td>197.0</td>\n      <td>0.620305</td>\n      <td>0.153520</td>\n      <td>0.230000</td>\n      <td>0.480000</td>\n      <td>0.670000</td>\n      <td>0.76000</td>\n      <td>0.790000</td>\n    </tr>\n    <tr>\n      <th>temperatureMax_1</th>\n      <td>197.0</td>\n      <td>93.153046</td>\n      <td>5.198585</td>\n      <td>87.910000</td>\n      <td>88.920000</td>\n      <td>89.740000</td>\n      <td>98.28000</td>\n      <td>106.580000</td>\n    </tr>\n    <tr>\n      <th>temperatureMax_2</th>\n      <td>197.0</td>\n      <td>93.202843</td>\n      <td>5.195089</td>\n      <td>88.030000</td>\n      <td>88.940000</td>\n      <td>89.740000</td>\n      <td>98.28000</td>\n      <td>106.580000</td>\n    </tr>\n    <tr>\n      <th>temperatureMax_3</th>\n      <td>197.0</td>\n      <td>93.259036</td>\n      <td>5.198720</td>\n      <td>88.140000</td>\n      <td>88.950000</td>\n      <td>89.830000</td>\n      <td>98.46000</td>\n      <td>106.580000</td>\n    </tr>\n    <tr>\n      <th>temperatureMin_1</th>\n      <td>197.0</td>\n      <td>74.582183</td>\n      <td>4.453832</td>\n      <td>70.060000</td>\n      <td>71.010000</td>\n      <td>71.830000</td>\n      <td>78.11000</td>\n      <td>82.950000</td>\n    </tr>\n    <tr>\n      <th>temperatureMin_2</th>\n      <td>197.0</td>\n      <td>74.603452</td>\n      <td>4.442115</td>\n      <td>70.170000</td>\n      <td>71.040000</td>\n      <td>71.830000</td>\n      <td>78.11000</td>\n      <td>82.950000</td>\n    </tr>\n    <tr>\n      <th>temperatureMin_3</th>\n      <td>197.0</td>\n      <td>74.635381</td>\n      <td>4.432682</td>\n      <td>70.230000</td>\n      <td>71.060000</td>\n      <td>71.840000</td>\n      <td>78.11000</td>\n      <td>82.950000</td>\n    </tr>\n    <tr>\n      <th>precipProbability_1</th>\n      <td>197.0</td>\n      <td>0.007665</td>\n      <td>0.026081</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.160000</td>\n    </tr>\n    <tr>\n      <th>precipProbability_2</th>\n      <td>197.0</td>\n      <td>0.008629</td>\n      <td>0.029131</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.190000</td>\n    </tr>\n    <tr>\n      <th>precipProbability_3</th>\n      <td>197.0</td>\n      <td>0.009289</td>\n      <td>0.030380</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.190000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 19
    }
   ],
   "source": [
    "# read the csv data into a pandas dataframe and set the date as the index\n",
    "# df = pd.read_csv('end-part2_df.csv').set_index('date')\n",
    "with open('end-part1_df.pkl', 'rb') as fp:\n",
    "    df = pickle.load(fp)\n",
    "\n",
    "# execute the describe() function and transpose the output so that it doesn't overflow the width of the screen\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df.index = df.index.values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 197 entries, 1.58652371064889e+18 to 1.60345811064889e+18\n",
      "Data columns (total 21 columns):\n",
      "temperatureMean        197 non-null float64\n",
      "temperatureMax         197 non-null float64\n",
      "temperatureMin         197 non-null float64\n",
      "temperatureMean_1      197 non-null float64\n",
      "temperatureMean_2      197 non-null float64\n",
      "temperatureMean_3      197 non-null float64\n",
      "dewPoint_1             197 non-null float64\n",
      "dewPoint_2             197 non-null float64\n",
      "dewPoint_3             197 non-null float64\n",
      "humidity_1             197 non-null float64\n",
      "humidity_2             197 non-null float64\n",
      "humidity_3             197 non-null float64\n",
      "temperatureMax_1       197 non-null float64\n",
      "temperatureMax_2       197 non-null float64\n",
      "temperatureMax_3       197 non-null float64\n",
      "temperatureMin_1       197 non-null float64\n",
      "temperatureMin_2       197 non-null float64\n",
      "temperatureMin_3       197 non-null float64\n",
      "precipProbability_1    197 non-null float64\n",
      "precipProbability_2    197 non-null float64\n",
      "precipProbability_3    197 non-null float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 33.9 KB\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# execute the info() function\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# First drop the maxtempm and mintempm from the dataframe\n",
    "#print(df)\n",
    "df = df.drop(['temperatureMin', 'temperatureMax'], axis=1)\n",
    "\n",
    "# X will be a pandas dataframe of all columns except meantempm\n",
    "X = df[[col for col in df.columns if col != 'temperatureMean']]\n",
    "\n",
    "# y will be a pandas series of the meantempm\n",
    "y = df['temperatureMean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# split data into training set and a temporary set\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training instances   157, Training features   18\n",
      "Validation instances 20, Validation features 18\n",
      "Testing instances    20, Testing features    18\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# split the remaining 20% of data evenly\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_tmp, y_tmp, test_size=0.5, random_state=23)\n",
    "\n",
    "X_train.shape, X_test.shape, X_val.shape\n",
    "print('Training instances   {}, Training features   {}'.format(X_train.shape[0], X_train.shape[1]))\n",
    "print('Validation instances {}, Validation features {}'.format(X_val.shape[0], X_val.shape[1]))\n",
    "print('Testing instances    {}, Testing features    {}'.format(X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column(col) for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "regressor = tf.estimator.DNNRegressor(feature_columns=feature_cols,\n",
    "                                      hidden_units=[50, 50],\n",
    "                                      model_dir='~/Projects/machine-learning-predict-weather/tf_models/tf_wx_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def wx_input_fn(X, y=None, num_epochs=None, shuffle=True, batch_size=400):\n",
    "    return tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "        x=X, y=y, num_epochs=num_epochs, shuffle=shuffle, batch_size=batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "W0417 21:29:10.211975 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:29:15.703247 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:29:16.392369 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:29:21.513385 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:29:22.192580 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:29:27.987326 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:29:29.111225 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:29:35.814572 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:29:36.581805 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:29:41.294070 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:29:41.995203 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:29:47.349151 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:29:49.045263 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:29:55.149936 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:29:55.847524 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:30:02.226734 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:30:03.585998 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:30:09.771588 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:30:10.447700 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 21:30:16.815125 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "{'average_loss': 1.0529233, 'label/mean': 83.93743, 'loss': 1.0529233, 'prediction/mean': 84.144264, 'global_step': 152400}\n",
      "{'average_loss': 1.0530407, 'label/mean': 83.93743, 'loss': 1.0530407, 'prediction/mean': 84.14494, 'global_step': 152800}\n",
      "{'average_loss': 1.0528708, 'label/mean': 83.93743, 'loss': 1.0528708, 'prediction/mean': 84.14497, 'global_step': 153200}\n",
      "{'average_loss': 1.0523304, 'label/mean': 83.93743, 'loss': 1.0523304, 'prediction/mean': 84.14408, 'global_step': 153600}\n",
      "{'average_loss': 1.0528333, 'label/mean': 83.93743, 'loss': 1.0528333, 'prediction/mean': 84.1456, 'global_step': 154000}\n",
      "{'average_loss': 1.0519695, 'label/mean': 83.93743, 'loss': 1.0519695, 'prediction/mean': 84.14397, 'global_step': 154400}\n",
      "{'average_loss': 1.0520322, 'label/mean': 83.93743, 'loss': 1.0520322, 'prediction/mean': 84.14457, 'global_step': 154800}\n",
      "{'average_loss': 1.0521231, 'label/mean': 83.93743, 'loss': 1.0521231, 'prediction/mean': 84.14518, 'global_step': 155200}\n",
      "{'average_loss': 1.0521799, 'label/mean': 83.93743, 'loss': 1.0521799, 'prediction/mean': 84.14566, 'global_step': 155600}\n",
      "{'average_loss': 1.052038, 'label/mean': 83.93743, 'loss': 1.052038, 'prediction/mean': 84.14573, 'global_step': 156000}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "evaluations = []\n",
    "STEPS = 400\n",
    "for i in range(10):\n",
    "    regressor.train(input_fn=wx_input_fn(X_train, y=y_train), steps=STEPS)\n",
    "    t = regressor.evaluate(input_fn=wx_input_fn(X_val,\n",
    "                                                           y_val,num_epochs=1,\n",
    "                                                               shuffle=False))\n",
    "    print(t)\n",
    "    evaluations.append(t)\n",
    "    #print(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'average_loss': 1.0548695,\n 'label/mean': 83.93743,\n 'loss': 1.0548695,\n 'prediction/mean': 84.14476,\n 'global_step': 148400}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 29
    }
   ],
   "source": [
    "evaluations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'average_loss': 1.0534436,\n 'label/mean': 83.93743,\n 'loss': 1.0534436,\n 'prediction/mean': 84.145065,\n 'global_step': 152000}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 30
    }
   ],
   "source": [
    "evaluations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'Loss (SSE)')"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 36
    },
    {
     "data": {
      "text/plain": "<Figure size 1008x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "loss_values = [ev['loss'] for ev in evaluations]\n",
    "training_steps = [ev['global_step'] for ev in evaluations]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "ax.scatter(x=training_steps, y=loss_values)\n",
    "ax.set_xlabel('Training steps (Epochs = steps / 2)')\n",
    "ax.set_ylabel('Loss (SSE)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "W0417 21:57:06.840577 101360 base_layer_v1.py:1808] Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "[79.95547  86.70685  78.65669  84.941864 79.99644  79.98505  92.30533\n",
      " 79.85306  79.7074   91.40236  78.49922  81.99409  89.108604 80.141235\n",
      " 79.9996   85.60927  90.08443  84.063934 78.40161  78.59789 ]\n",
      "The Explained Variance: 0.99\n",
      "The Mean Absolute Error: 0.32 degrees Celcius\n",
      "The Median Absolute Error: 0.25 degrees Celcius\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "pred = regressor.predict(input_fn=wx_input_fn(X_test,\n",
    "                                              num_epochs=1,\n",
    "                                              shuffle=False))\n",
    "predictions = np.array([p['predictions'][0] for p in pred])\n",
    "print(predictions)\n",
    "\n",
    "print('The Explained Variance: %.2f' % explained_variance_score(y_test, predictions))\n",
    "print('The Mean Absolute Error: %.2f degrees Celcius' % mean_absolute_error(y_test, predictions))\n",
    "print('The Median Absolute Error: %.2f degrees Celcius' % median_absolute_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}